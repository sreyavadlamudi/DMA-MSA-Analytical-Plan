# -*- coding: utf-8 -*-
"""MGSC410 Project4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K448Hdi67WU88pTqUso3YlbB0D1bAAjk
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import random
from plotnine import *
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler #Z-score variables
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import train_test_split # simple TT split cv
from sklearn.model_selection import KFold # k-fold cv
from sklearn.model_selection import LeaveOneOut #LOO cv
from sklearn.model_selection import cross_val_score # cross validation metrics
from sklearn.model_selection import cross_val_predict # cross validation metrics
from sklearn.preprocessing import LabelBinarizer


from sklearn.linear_model import LinearRegression # Linear Regression Model
from sklearn.preprocessing import StandardScaler #Z-score variables
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score #model evaluation

from sklearn.model_selection import train_test_split # simple TT split cv
from sklearn.model_selection import KFold # k-fold cv
from sklearn.model_selection import LeaveOneOut #LOO cv
from sklearn.model_selection import cross_val_score # cross validation metrics
from sklearn.model_selection import cross_val_predict # cross validation metrics

DMAdata = pd.read_csv("https://raw.githubusercontent.com/sreyavadlamudi/MGSC410/main/PI-18803%20DMAs.csv?token=GHSAT0AAAAAACBS7WLYGZLOD4274N3CJLE2ZCCA2JQ")
DMAdata = DMAdata.dropna()
DMAdata = DMAdata.reset_index()
DMAdata

DMAdata['Household Count'] = DMAdata['Household Count'].astype(str)
DMAdata['Household Count'] = DMAdata['Household Count'].str.replace(',', '').astype(float)
DMAdata['Household Count'] = pd.to_numeric(DMAdata['Household Count'])

DMAdata['Med HHld Income'] = DMAdata['Med HHld Income'].astype(str)
DMAdata['Med HHld Income'] = DMAdata['Med HHld Income'].str.replace(',', '').str.replace('$', '').astype(float)
DMAdata['Med HHld Income'] = pd.to_numeric(DMAdata['Med HHld Income'])

DMAdata['HHlds 2+ Vehicles'] = DMAdata['HHlds 2+ Vehicles'].astype(str)
DMAdata['HHlds 2+ Vehicles'] = DMAdata['HHlds 2+ Vehicles'].str.replace(',', '').astype(float)
DMAdata['HHlds 2+ Vehicles'] = pd.to_numeric(DMAdata['HHlds 2+ Vehicles'])

DMAdata['Multi-Race'] = DMAdata['Multi-Race'].astype(str)
DMAdata['Multi-Race'] = DMAdata['Multi-Race'].str.replace(',', '').astype(float)
DMAdata['Multi-Race'] = pd.to_numeric(DMAdata['Multi-Race'])

#df_sorted = DMAdata.sort_values(by=['Med HHld Income','Household Count','HHlds 2+ Vehicles'], ascending=False)
df_sorted = DMAdata.sort_values(by=['Multi-Race'], ascending=False)

# Select the top 10 rows
top_10_states = df_sorted.head(10)

# Print the top 10 states
print(top_10_states)

#Linear Regression
predictors = ["White", "African American", "American Indian", "Asian", "Hawaiian/Pacific Islander", "Other Race", "Multi-Race", "Hispanic"]

DMAdata['Med HHld Income'] = DMAdata['Med HHld Income'].astype(str)
DMAdata['Med HHld Income'] = DMAdata['Med HHld Income'].str.replace(',', '').str.replace('$', '').astype(float)
DMAdata['Med HHld Income'] = pd.to_numeric(DMAdata['Med HHld Income'])

DMAdata['White'] = DMAdata['White'].astype(str)
DMAdata['White'] = DMAdata['White'].str.replace(',', '').astype(float)
DMAdata['White'] = pd.to_numeric(DMAdata['White'])

DMAdata['African American'] = DMAdata['African American'].astype(str)
DMAdata['African American'] = DMAdata['African American'].str.replace(',', '').astype(float)
DMAdata['African American'] = pd.to_numeric(DMAdata['African American'])

DMAdata['American Indian'] = DMAdata['American Indian'].astype(str)
DMAdata['American Indian'] = DMAdata['American Indian'].str.replace(',', '').astype(float)
DMAdata['American Indian'] = pd.to_numeric(DMAdata['American Indian'])

DMAdata['Asian'] = DMAdata['Asian'].astype(str)
DMAdata['Asian'] = DMAdata['Asian'].str.replace(',', '').astype(float)
DMAdata['Asian'] = pd.to_numeric(DMAdata['Asian'])

DMAdata['Hawaiian/Pacific Islander'] = DMAdata['Hawaiian/Pacific Islander'].astype(str)
DMAdata['Hawaiian/Pacific Islander'] = DMAdata['Hawaiian/Pacific Islander'].str.replace(',', '').astype(float)
DMAdata['Hawaiian/Pacific Islander'] = pd.to_numeric(DMAdata['Hawaiian/Pacific Islander'])

DMAdata['Other Race'] = DMAdata['Other Race'].astype(str)
DMAdata['Other Race'] = DMAdata['Other Race'].str.replace(',', '').astype(float)
DMAdata['Other Race'] = pd.to_numeric(DMAdata['Other Race'])

DMAdata['Multi-Race'] = DMAdata['Multi-Race'].astype(str)
DMAdata['Multi-Race'] = DMAdata['Multi-Race'].str.replace(',', '').astype(float)
DMAdata['Multi-Race'] = pd.to_numeric(DMAdata['Multi-Race'])

DMAdata['Hispanic'] = DMAdata['Hispanic'].astype(str)
DMAdata['Hispanic'] = DMAdata['Hispanic'].str.replace(',', '').astype(float)
DMAdata['Hispanic'] = pd.to_numeric(DMAdata['Hispanic'])


X_train, X_test, y_train, y_test = train_test_split(DMAdata[predictors],DMAdata["Med HHld Income"], test_size = 0.2)

z = StandardScaler()
z.fit(X_train[predictors])
X_train = z.transform(X_train[predictors])
X_test = z.transform(X_test[predictors])

DMAModel = LinearRegression()
DMAModel.fit(X_train, y_train)

coefficients = pd.DataFrame({"Coef": DMAModel.coef_,
                            "Names": predictors})
coefficients
(ggplot(coefficients, aes(x="Names", y="Coef", fill = "Names"))+geom_bar(stat="identity")+labs(x="Names", y="Income")+
 ggtitle("Income in relation to Ethnicity")+theme_minimal()+theme(axis_text_x=element_blank()))    #Chose Top 3

import matplotlib.pyplot as plt
import numpy as np

#DMA_Name in relation to Area and Population:

DMAdataArea = DMAdata.sort_values(by='Area', ascending=False)

# Select the top ten rows by 'Area'
top_ten_area = DMAdataArea.head(10)

# Create a pie chart of the top ten rows by 'Area'
fig, ax = plt.subplots()
ax.pie(top_ten_area['Area'], labels=top_ten_area['DMA Name'], autopct='%1.1f%%')

# Add a chart title
ax.set(title='Top Ten Designated Markets by Area')

# Display the chart
plt.show()

# Remove commas in the 'Population' column
DMAdata['Population 18+'] = DMAdata['Population 18+'].astype(str)
DMAdata['Population 18+'] = DMAdata['Population 18+'].str.replace(',', '')

# Convert the 'Population' column to numeric
DMAdata['Population 18+'] = pd.to_numeric(DMAdata['Population 18+'])

# Sort the DataFrame by 'Population' in descending order
DMApopulation = DMAdata.sort_values(by='Population 18+', ascending=False)

# Select the top ten rows by 'Population'
top_ten_pop = DMApopulation.head(10)

# Create a pie chart of the top ten rows by 'Population'
fig, ax = plt.subplots()
ax.pie(top_ten_pop['Population 18+'], labels=top_ten_pop['DMA Name'], autopct='%1.1f%%')

# Add a chart title
ax.set(title='Top Ten Populated Designated Market Areas')

# Display the chart
plt.show()

#Median household count: 301,762 so anything greater than this would be ideal

#Population and Area of top 10 DMAs in relation to Household count:
# convert population and household count to numeric type
DMAdata['Population 18+'] = DMAdata['Population 18+'].astype(str)
DMAdata['Population 18+'] = DMAdata['Population 18+'].str.replace(',', '').astype(float)
DMAdata['Population 18+'] = pd.to_numeric(DMAdata['Population 18+'])
DMAdata['Household Count'] = DMAdata['Household Count'].astype(str)
DMAdata['Household Count'] = DMAdata['Household Count'].str.replace(',', '').astype(float)
DMAdata['Household Count'] = pd.to_numeric(DMAdata['Household Count'])

DMAdata['HHlds No Vehicles'] = DMAdata['HHlds No Vehicles'].astype(str)
DMAdata['HHlds No Vehicles'] = DMAdata['HHlds No Vehicles'].str.replace(',', '').astype(float)
DMAdata['HHlds No Vehicles'] = pd.to_numeric(DMAdata['HHlds No Vehicles'])

DMAdata['HHlds 1-2 Vehicles'] = DMAdata['HHlds 1-2 Vehicles'].astype(str)
DMAdata['HHlds 1-2 Vehicles'] = DMAdata['HHlds 1-2 Vehicles'].str.replace(',', '').astype(float)
DMAdata['HHlds 1-2 Vehicles'] = pd.to_numeric(DMAdata['HHlds 1-2 Vehicles'])

DMAdata['HHlds 2+ Vehicles'] = DMAdata['HHlds 2+ Vehicles'].astype(str)
DMAdata['HHlds 2+ Vehicles'] = DMAdata['HHlds 2+ Vehicles'].str.replace(',', '').astype(float)
DMAdata['HHlds 2+ Vehicles'] = pd.to_numeric(DMAdata['HHlds 2+ Vehicles'])

DMAdata['HHld Exp - Public Transport'] = DMAdata['HHld Exp - Public Transport'].astype(str)
DMAdata['HHld Exp - Public Transport'] = DMAdata['HHld Exp - Public Transport'].str.replace(',', '').astype(float)
DMAdata['HHld Exp - Public Transport'] = pd.to_numeric(DMAdata['HHld Exp - Public Transport'])

DMAdata['HHld Exp - Intercity Bus Fare'] = DMAdata['HHld Exp - Intercity Bus Fare'].astype(str)
DMAdata['HHld Exp - Intercity Bus Fare'] = DMAdata['HHld Exp - Intercity Bus Fare'].str.replace(',', '').astype(float)
DMAdata['HHld Exp - Intercity Bus Fare'] = pd.to_numeric(DMAdata['HHld Exp - Intercity Bus Fare'])

DMAdata['HHld Exp - Mass Transit'] = DMAdata['HHld Exp - Mass Transit'].astype(str)
DMAdata['HHld Exp - Mass Transit'] = DMAdata['HHld Exp - Mass Transit'].str.replace(',', '').astype(float)
DMAdata['HHld Exp - Mass Transit'] = pd.to_numeric(DMAdata['HHld Exp - Mass Transit'])

DMAdata['HHld Exp - Taxi'] = DMAdata['HHld Exp - Taxi'].astype(str)
DMAdata['HHld Exp - Taxi'] = DMAdata['HHld Exp - Taxi'].str.replace(',', '').astype(float)
DMAdata['HHld Exp - Taxi'] = pd.to_numeric(DMAdata['HHld Exp - Taxi'])

DMAdata['HHld Exp - Other Public Transportation'] = DMAdata['HHld Exp - Other Public Transportation'].astype(str)
DMAdata['HHld Exp - Other Public Transportation'] = DMAdata['HHld Exp - Other Public Transportation'].str.replace(',', '').astype(float)
DMAdata['HHld Exp - Other Public Transportation'] = pd.to_numeric(DMAdata['HHld Exp - Other Public Transportation'])


# filter for top ten areas and populations, and households greater than 301,762(median)

DMAMix = (DMAdata["DMA Name"] == "Non-DMA Areas") | (DMAdata["DMA Name"] == "Salt Lake City") | (DMAdata["DMA Name"] == "Albuquerque-Santa Fe") | (DMAdata["DMA Name"] == "Denver") | (DMAdata["DMA Name"] == "Phoenix") | (DMAdata["DMA Name"] == "Minot-Bismark") | (DMAdata["DMA Name"] == "Wichita-Hutchinson") | (DMAdata["DMA Name"] == "Spokane") | (DMAdata["DMA Name"] == "Billings") | (DMAdata["DMA Name"] == "Reno") | (DMAdata["DMA Name"] == "Los Angeles")| (DMAdata["DMA Name"] == "Chicago")| (DMAdata["DMA Name"] == "Philadelphia")| (DMAdata["DMA Name"] == "San Francisco-Oakland-San Jose")| (DMAdata["DMA Name"] == "Dallas-Fort Worth")| (DMAdata["DMA Name"] == "Washington DC")| (DMAdata["DMA Name"] == "Houston")| (DMAdata["DMA Name"] == "Boston-Manchester")| (DMAdata["DMA Name"] == "Atlanta")| (DMAdata["DMA Name"] == "New York")
DMAMix2 = DMAdata.loc[DMAMix & (DMAdata["Household Count"]>301762)]

print("Number of observations in DMAMix2:", len(DMAMix2))

print(ggplot(DMAMix2, aes(x = "DMA Name", y = "Household Count", fill = "DMA Name"))
+ ggtitle("Household count in relation to area and population")
+ theme_minimal()+theme(axis_text_x=element_blank())+ geom_bar(stat='identity'))

#Average No Vehicles: 50,562
#Average 1 Vehicle: 195,827
#Average 2+ Vehicles: 348,574

#Since majority of households have 2+ vehicles, I decided to look at that factor within the 17 cities I have already distinguished as key.

#I also then looked at public transportation, Intercity Bus Fare, Mass Transit, Taxi, and Other Public Transporation because it would be easier for people to get to places even if they do not have a vehicle. This would be key in a competitive market.

#No Vehicle in comparison to 1 Vehicle and 2 Vehicle households


#as population increases, the more households with 2 vehicles increases
#check usage of each

#Whatever is most prominent, choose those cities based on transportation

# create a new column to sum up all transportation types
#DMAMix2['Total Transportation'] = DMAMix2['HHlds No Vehicles'] + DMAMix2['HHlds 1-2 Vehicles'] + DMAMix2['HHlds 2+ Vehicles'] + DMAMix2['HHld Exp - Public Transport'] + DMAMix2['HHld Exp - Intercity Bus Fare'] + DMAMix2['HHld Exp - Mass Transit'] + DMAMix2['HHld Exp - Taxi'] + DMAMix2['HHld Exp - Other Public Transportation']


transportation_columns = ['HHlds No Vehicles', 'HHlds 1-2 Vehicles', 'HHlds 2+ Vehicles','HHld Exp - Public Transport', 'HHld Exp - Intercity Bus Fare', 'HHld Exp - Mass Transit', 'HHld Exp - Taxi', 'HHld Exp - Other Public Transportation']

DMAMix2['Total Transportation'] = DMAMix2[transportation_columns].sum(axis=1)
most_prominent_transportation_index = DMAMix2['Total Transportation'].idxmax()
most_prominent_transportation_name = transportation_columns[most_prominent_transportation_index]
col_sums = DMAMix2[['HHlds No Vehicles', 'HHlds 1-2 Vehicles', 'HHlds 2+ Vehicles', 'HHld Exp - Public Transport', 'HHld Exp - Intercity Bus Fare', 'HHld Exp - Mass Transit', 'HHld Exp - Taxi', 'HHld Exp - Other Public Transportation']].sum()

print(col_sums)


print("The most prominent transportation mode in the dataset is:", most_prominent_transportation_name)   #cut down cities based on this information

MSAdata = pd.read_csv("https://raw.githubusercontent.com/sreyavadlamudi/MGSC410/main/MSAdata.csv?token=GHSAT0AAAAAACBN6WFVIMERR4PE7ZK24N76ZB3QT2Q")
MSAdata = MSAdata.dropna()
MSAdata = MSAdata.reset_index()
MSAdata

#MSA places selected from top DMA and very similar so good sign(Majority in West and South, least in Midwest, just Chicago)
#Top two consumer units are(took the some):
  #NE: $292,925
  #Midwest: $263,750 - this backs up what I found earlier
  #West: $315,465
  #South: $278,101

#Look at these specific places:
  #West: LA, SF, Phoenix, Denver
  #South: DC, Atlanta, Dallas, Houtson
  #NE: NY, Philadelphia, Boston

#Other options after I look thru stores
#Take more averages for individual states/other qualitative number analysis


# Calculate the total expenditure for each item by summing up the values for all states
item_totals = MSAdata.iloc[:, 3:].sum()

# Sort the items in descending order based on their total expenditure
item_totals = item_totals.sort_values(ascending=False)

# Create a bar chart to show the relative proportions of the total expenditure for each item
plt.bar(item_totals.index, item_totals.values)
plt.xticks(rotation=90)
plt.xlabel('Item')
plt.ylabel('Total Expenditure')
plt.title('Total Expenditure by Item')
plt.show()

#Linear Regression for combined All expenditures from all places(NE, South, Midwest, and West)
MSALinear = pd.read_csv("https://raw.githubusercontent.com/sreyavadlamudi/MGSC410/main/MSALinear.csv?token=GHSAT0AAAAAACBN6WFVXIXMBKF6VDZPKUDSZB3SQ6A")
MSALinear = MSALinear.dropna()
MSALinear = MSALinear.reset_index()
MSALinear


MSALinear['Household operations'] = MSALinear['Household operations'].astype(str)
MSALinear['Household operations'] = MSALinear['Household operations'].str.replace(',', '').astype(float)
MSALinear['Household operations'] = pd.to_numeric(MSALinear['Household operations'])

MSALinear['Average annual expenditure'] = MSALinear['Average annual expenditure'].astype(str)
MSALinear['Average annual expenditure'] = MSALinear['Average annual expenditure'].str.replace(',', '').astype(float)
MSALinear['Average annual expenditure'] = pd.to_numeric(MSALinear['Average annual expenditure'])

MSALinear['Housekeeping supplies'] = MSALinear['Housekeeping supplies'].astype(str)
MSALinear['Housekeeping supplies'] = MSALinear['Housekeeping supplies'].str.replace(',', '').astype(float)
MSALinear['Housekeeping supplies'] = pd.to_numeric(MSALinear['Housekeeping supplies'])

MSALinear['Household furnishings and equipment'] = MSALinear['Household furnishings and equipment'].astype(str)
MSALinear['Household furnishings and equipment'] = MSALinear['Household furnishings and equipment'].str.replace(',', '').astype(float)
MSALinear['Household furnishings and equipment'] = pd.to_numeric(MSALinear['Household furnishings and equipment'])

MSALinear['Apparel and services'] = MSALinear['Apparel and services'].astype(str)
MSALinear['Apparel and services'] = MSALinear['Apparel and services'].str.replace(',', '').astype(float)
MSALinear['Apparel and services'] = pd.to_numeric(MSALinear['Apparel and services'])

MSALinear['Transportation'] = MSALinear['Transportation'].astype(str)
MSALinear['Transportation'] = MSALinear['Transportation'].str.replace(',', '').astype(float)
MSALinear['Transportation'] = pd.to_numeric(MSALinear['Transportation'])

MSALinear['Vehicle purchases (net outlay)'] = MSALinear['Vehicle purchases (net outlay)'].astype(str)
MSALinear['Vehicle purchases (net outlay)'] = MSALinear['Vehicle purchases (net outlay)'].str.replace(',', '').astype(float)
MSALinear['Vehicle purchases (net outlay)'] = pd.to_numeric(MSALinear['Vehicle purchases (net outlay)'])

MSALinear['Gasoline, other fuels, and motor oil'] = MSALinear['Gasoline, other fuels, and motor oil'].astype(str)
MSALinear['Gasoline, other fuels, and motor oil'] = MSALinear['Gasoline, other fuels, and motor oil'].str.replace(',', '').astype(float)
MSALinear['Gasoline, other fuels, and motor oil'] = pd.to_numeric(MSALinear['Gasoline, other fuels, and motor oil'])

MSALinear['Other vehicle expenses'] = MSALinear['Other vehicle expenses'].astype(str)
MSALinear['Other vehicle expenses'] = MSALinear['Other vehicle expenses'].str.replace(',', '').astype(float)
MSALinear['Other vehicle expenses'] = pd.to_numeric(MSALinear['Other vehicle expenses'])

MSALinear['Public and other transportation'] = MSALinear['Public and other transportation'].astype(str)
MSALinear['Public and other transportation'] = MSALinear['Public and other transportation'].str.replace(',', '').astype(float)
MSALinear['Public and other transportation'] = pd.to_numeric(MSALinear['Public and other transportation'])

MSALinear['Healthcare'] = MSALinear['Healthcare'].astype(str)
MSALinear['Healthcare'] = MSALinear['Healthcare'].str.replace(',', '').astype(float)
MSALinear['Healthcare'] = pd.to_numeric(MSALinear['Healthcare'])

MSALinear['Entertainment'] = MSALinear['Entertainment'].astype(str)
MSALinear['Entertainment'] = MSALinear['Entertainment'].str.replace(',', '').astype(float)
MSALinear['Entertainment'] = pd.to_numeric(MSALinear['Entertainment'])

MSALinear['Personal care products and services'] = MSALinear['Personal care products and services'].astype(str)
MSALinear['Personal care products and services'] = MSALinear['Personal care products and services'].str.replace(',', '').astype(float)
MSALinear['Personal care products and services'] = pd.to_numeric(MSALinear['Personal care products and services'])

MSALinear['Reading'] = MSALinear['Reading'].astype(str)
MSALinear['Reading'] = MSALinear['Reading'].str.replace(',', '').astype(float)
MSALinear['Reading'] = pd.to_numeric(MSALinear['Reading'])

MSALinear['Education'] = MSALinear['Education'].astype(str)
MSALinear['Education'] = MSALinear['Education'].str.replace(',', '').astype(float)
MSALinear['Education'] = pd.to_numeric(MSALinear['Education'])

MSALinear['Tobacco products and smoking supplies'] = MSALinear['Tobacco products and smoking supplies'].astype(str)
MSALinear['Tobacco products and smoking supplies'] = MSALinear['Tobacco products and smoking supplies'].str.replace(',', '').astype(float)
MSALinear['Tobacco products and smoking supplies'] = pd.to_numeric(MSALinear['Tobacco products and smoking supplies'])

MSALinear['Miscellaneous'] = MSALinear['Miscellaneous'].astype(str)
MSALinear['Miscellaneous'] = MSALinear['Miscellaneous'].str.replace(',', '').astype(float)
MSALinear['Miscellaneous'] = pd.to_numeric(MSALinear['Miscellaneous'])

MSALinear['Cash contributions'] = MSALinear['Cash contributions'].astype(str)
MSALinear['Cash contributions'] = MSALinear['Cash contributions'].str.replace(',', '').astype(float)
MSALinear['Cash contributions'] = pd.to_numeric(MSALinear['Cash contributions'])

MSALinear['Life and other personal insurance'] = MSALinear['Life and other personal insurance'].astype(str)
MSALinear['Life and other personal insurance'] = MSALinear['Life and other personal insurance'].str.replace(',', '').astype(float)
MSALinear['Life and other personal insurance'] = pd.to_numeric(MSALinear['Life and other personal insurance'])

MSALinear['Personal insurance and pensions'] = MSALinear['Personal insurance and pensions'].astype(str)
MSALinear['Personal insurance and pensions'] = MSALinear['Personal insurance and pensions'].str.replace(',', '').astype(float)
MSALinear['Personal insurance and pensions'] = pd.to_numeric(MSALinear['Personal insurance and pensions'])

MSALinear['Pensions and Social Security'] = MSALinear['Pensions and Social Security'].astype(str)
MSALinear['Pensions and Social Security'] = MSALinear['Pensions and Social Security'].str.replace(',', '').astype(float)
MSALinear['Pensions and Social Security'] = pd.to_numeric(MSALinear['Pensions and Social Security'])

MSALinear['Utilities, fuels, and public services'] = MSALinear['Utilities, fuels, and public services'].astype(str)
MSALinear['Utilities, fuels, and public services'] = MSALinear['Utilities, fuels, and public services'].str.replace(',', '').astype(float)
MSALinear['Utilities, fuels, and public services'] = pd.to_numeric(MSALinear['Utilities, fuels, and public services'])

MSALinear['Other lodging'] = MSALinear['Other lodging'].astype(str)
MSALinear['Other lodging'] = MSALinear['Other lodging'].str.replace(',', '').astype(float)
MSALinear['Other lodging'] = pd.to_numeric(MSALinear['Other lodging'])

MSALinear['Rented dwellings'] = MSALinear['Rented dwellings'].astype(str)
MSALinear['Rented dwellings'] = MSALinear['Rented dwellings'].str.replace(',', '').astype(float)
MSALinear['Rented dwellings'] = pd.to_numeric(MSALinear['Rented dwellings'])

MSALinear['Owned dwellings'] = MSALinear['Owned dwellings'].astype(str)
MSALinear['Owned dwellings'] = MSALinear['Owned dwellings'].str.replace(',', '').astype(float)
MSALinear['Owned dwellings'] = pd.to_numeric(MSALinear['Owned dwellings'])

MSALinear['Shelter'] = MSALinear['Shelter'].astype(str)
MSALinear['Shelter'] = MSALinear['Shelter'].str.replace(',', '').astype(float)
MSALinear['Shelter'] = pd.to_numeric(MSALinear['Shelter'])

MSALinear['Housing'] = MSALinear['Housing'].astype(str)
MSALinear['Housing'] = MSALinear['Housing'].str.replace(',', '').astype(float)
MSALinear['Housing'] = pd.to_numeric(MSALinear['Housing'])

MSALinear['Alcoholic beverages'] = MSALinear['Alcoholic beverages'].astype(str)
MSALinear['Alcoholic beverages'] = MSALinear['Alcoholic beverages'].str.replace(',', '').astype(float)
MSALinear['Alcoholic beverages'] = pd.to_numeric(MSALinear['Alcoholic beverages'])

MSALinear['Food away from home'] = MSALinear['Food away from home'].astype(str)
MSALinear['Food away from home'] = MSALinear['Food away from home'].str.replace(',', '').astype(float)
MSALinear['Food away from home'] = pd.to_numeric(MSALinear['Food away from home'])

MSALinear['Other food at home'] = MSALinear['Other food at home'].astype(str)
MSALinear['Other food at home'] = MSALinear['Other food at home'].str.replace(',', '').astype(float)
MSALinear['Other food at home'] = pd.to_numeric(MSALinear['Other food at home'])

MSALinear['Fruits and vegetables'] = MSALinear['Fruits and vegetables'].astype(str)
MSALinear['Fruits and vegetables'] = MSALinear['Fruits and vegetables'].str.replace(',', '').astype(float)
MSALinear['Fruits and vegetables'] = pd.to_numeric(MSALinear['Fruits and vegetables'])

MSALinear['Dairy products'] = MSALinear['Dairy products'].astype(str)
MSALinear['Dairy products'] = MSALinear['Dairy products'].str.replace(',', '').astype(float)
MSALinear['Dairy products'] = pd.to_numeric(MSALinear['Dairy products'])

MSALinear['Meats, poultry, fish, and eggs'] = MSALinear['Meats, poultry, fish, and eggs'].astype(str)
MSALinear['Meats, poultry, fish, and eggs'] = MSALinear['Meats, poultry, fish, and eggs'].str.replace(',', '').astype(float)
MSALinear['Meats, poultry, fish, and eggs'] = pd.to_numeric(MSALinear['Meats, poultry, fish, and eggs'])

MSALinear['Cereals and bakery products'] = MSALinear['Cereals and bakery products'].astype(str)
MSALinear['Cereals and bakery products'] = MSALinear['Cereals and bakery products'].str.replace(',', '').astype(float)
MSALinear['Cereals and bakery products'] = pd.to_numeric(MSALinear['Cereals and bakery products'])

MSALinear['Food at home'] = MSALinear['Food at home'].astype(str)
MSALinear['Food at home'] = MSALinear['Food at home'].str.replace(',', '').astype(float)
MSALinear['Food at home'] = pd.to_numeric(MSALinear['Food at home'])

MSALinear['Food'] = MSALinear['Food'].astype(str)
MSALinear['Food'] = MSALinear['Food'].str.replace(',', '').astype(float)
MSALinear['Food'] = pd.to_numeric(MSALinear['Food'])

#which states have biggest impact with whatever coefficient is the biggest

predictors = ["Food", "Food at home", "Cereals and bakery products", "Meats, poultry, fish, and eggs", "Dairy products", "Fruits and vegetables", "Other food at home", "Food away from home", "Alcoholic beverages", "Housing", "Shelter", "Owned dwellings", "Rented dwellings", "Other lodging", "Utilities, fuels, and public services", "Household operations", "Housekeeping supplies", "Household furnishings and equipment", "Apparel and services", "Transportation", "Vehicle purchases (net outlay)", "Gasoline, other fuels, and motor oil", "Other vehicle expenses", "Public and other transportation", "Healthcare", "Entertainment", "Personal care products and services", "Reading", "Education", "Tobacco products and smoking supplies", "Miscellaneous", "Cash contributions", "Personal insurance and pensions", "Life and other personal insurance", "Pensions and Social Security"]

X_train, X_test, y_train, y_test = train_test_split(MSALinear[predictors],MSALinear["Average annual expenditure"], test_size = 0.2)

z = StandardScaler()
z.fit(X_train[predictors])
X_train = z.transform(X_train[predictors])
X_test = z.transform(X_test[predictors])

MSAModel = LinearRegression()
MSAModel.fit(X_train, y_train)

coefficients = pd.DataFrame({"Coef": MSAModel.coef_,
                            "Names": predictors})
coefficients
(ggplot(coefficients, aes(x="Names", y="Coef", fill = "Names"))+geom_bar(stat="identity")+labs(x="Names", y="Average Annual Expenditure")+
 ggtitle("Avg Annual Expenditures in relation to Items")+theme_minimal()+theme(axis_text_x=element_blank()))



DMAstores = pd.read_csv("https://raw.githubusercontent.com/sreyavadlamudi/MGSC410/main/DMAstores.csv?token=GHSAT0AAAAAACBN6WFVPKPUIWQR6CRC6A6CZB3VFIA")
#check if above is the right data
DMAstores = DMAstores.dropna()
DMAstores = DMAstores.reset_index()
DMAstores

#Largest sized store
#From MSA and DMA data, pick most significant stores

#Top 10 Stores
  #Analyze these stores with the sales dataset as well as overall


DMAstores = DMAstores.sort_values(by='Size', ascending=False)

# Select the top ten rows by 'Area'
top_ten_size = DMAstores.head(10)

# Create a pie chart of the top ten rows by 'Area'
print(top_ten_size)

#Stores:
#20
#Weighted Temperature: 67.82
#Weighted Fuel Price: 3151.95
#Weighted CPI: 1965212811
#Weighted Unemployment: 7612.85
#Weighted IsHoliday: 0

#Do for all if necessary



#DMA:
#places with the largest area so there is room for a store opening
#out of those places, the ones with the biggest population with a larger household would be beneficial market for a store opening
#out of those places, which transportation is also most prominent(analyze charts in DMA given)
#ethnicity pie chart?

#MSA:
#compile the files and linear regression to see which factors are the biggest contribution to average annual expenditure
#look at the top three places for expenditures as well and compare to the top three in DMA
#also look at household specific children under 18 because more supplies will be needed
#look at transporation as well and compare to DMA

#DMA store dataset(out of the top places in DMA and MSA, look at the specific stores in detail)
#Store info files - merged averages because the file was too large to cooperate otherwise
#a model, maybe logisitic or clustering?
#combine features.csv and sales-data.csv
#look at all stores first and relationships(linear regression and bar graphs) but also look specifically at the DMA stores